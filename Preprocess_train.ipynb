{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_audio_video(dest, filename, youtube_id, start_time, end_time):\n",
    "    sr = 16000\n",
    "    link = 'https://www.youtube.com/watch?v='+youtube_id\n",
    "    \n",
    "    # download video stream and split into frames\n",
    "    command = 'cd %s;' % dest\n",
    "    command += 'ffmpeg -i $(youtube-dl -f ”mp4“ --get-url ' + link + ') ' + '-c:v h264 -c:a copy -ss %s -to %s %s.mp4;' \\\n",
    "               % (start_time, end_time, filename)\n",
    "    command += 'ffmpeg -i %s.mp4 -vf fps=25 %s-%%02d.jpg;' % (filename, filename)\n",
    "    os.system(command)\n",
    "    \n",
    "    # download audio stream\n",
    "    command = 'cd %s;' % dest\n",
    "    command += 'youtube-dl -x --audio-format wav -o o' + filename + '.wav ' + link + ';'\n",
    "    command += 'ffmpeg -i o%s.wav -ar %d -ac 1 %s.wav;' % (filename,sr,filename)\n",
    "    command += 'rm o%s.wav' % filename\n",
    "    os.system(command);\n",
    "    \n",
    "    # time crop\n",
    "    length = end_time - start_time\n",
    "    command = 'cd %s;' % dest\n",
    "    command += 'sox %s.wav preprocessed_%s.wav trim %s %s;' % (filename,filename,start_time,length)\n",
    "    command += 'rm %s.wav' % filename\n",
    "    os.system(command);\n",
    "    preprocessed_filename = dest + '/preprocessed_'+ filename + '.wav';\n",
    "    \n",
    "    # normalize\n",
    "    audio,_= lr.load(preprocessed_filename,sr=16000)\n",
    "    max_amplitude = np.max(np.abs(audio))\n",
    "    norm_audio = np.divide(audio,max_amplitude)\n",
    "    wavfile.write(preprocessed_filename, 16000, norm_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_box_check(faces,x,y):\n",
    "    # check the center\n",
    "    for face in faces:\n",
    "        bounding_box = face['box']\n",
    "        if(bounding_box[1]<0):\n",
    "            bounding_box[1] = 0\n",
    "        if(bounding_box[0]<0):\n",
    "            bounding_box[0] = 0\n",
    "        if(bounding_box[0]-50>x or bounding_box[0]+bounding_box[2]+50<x):\n",
    "            continue\n",
    "        if (bounding_box[1]-50 > y or bounding_box[1] + bounding_box[3]+50 < y):\n",
    "            continue\n",
    "        return bounding_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft(data, fft_size=512, step_size=160):\n",
    "    pad = np.zeros(192,)\n",
    "    data = np.concatenate((data,pad),axis=0)\n",
    "    window = np.concatenate((np.zeros((56,)),np.hanning(fft_size-112),np.zeros((56,))),axis=0)\n",
    "    win_num = (len(data) - fft_size) // step_size\n",
    "    out = np.ndarray((win_num, fft_size), dtype=data.dtype)\n",
    "    for i in range(win_num):\n",
    "        left = int(i * step_size)\n",
    "        right = int(left + fft_size)\n",
    "        out[i] = data[left: right] * window\n",
    "    F = np.fft.rfft(out, axis=1)\n",
    "    D = np.zeros((F.shape[0],F.shape[1],2))\n",
    "    D[:,:,0] = np.real(F)\n",
    "    D[:,:,1] = np.imag(F)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_ratio_mask(mix, isolated):\n",
    "    epsilon = 1e-8\n",
    "    Yr = mix[:,:,0];\n",
    "    Yi = mix[:,:,1];\n",
    "    Sr = isolated[:,:,0];\n",
    "    Si = isolated[:,:,1]\n",
    "    mask_num_real = Yr*Sr + Yi*Si\n",
    "    mask_num_imag = Yr*Si - Yi*Sr\n",
    "    mask_den = np.square(Yr)+np.square(Yi)\n",
    "    \n",
    "    mask = np.zeros(np.shape(mix))\n",
    "    mask[:,:,0] = mask_num_real / (mask_den + epsilon)\n",
    "    mask[:,:,1] = mask_num_imag / (mask_den + epsilon)\n",
    "    \n",
    "    C = 0.1\n",
    "    K = 10\n",
    "    \n",
    "    num = 1-np.exp(-C*mask)\n",
    "    den = 1+np.exp(-C*mask)\n",
    "    num[num == np.inf] = 1\n",
    "    num[num == -np.inf] = -1\n",
    "    den[den == np.inf] = 1\n",
    "    den[den == -np.inf] = -1\n",
    "    \n",
    "    return K*num/den;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detect(file,detector,frame_path,x,y):\n",
    "    name = file.replace('.jpg', '').split('-')\n",
    "    img = cv2.imread('%s%s'%(frame_path,file))\n",
    "    x = img.shape[1] * x\n",
    "    y = img.shape[0] * y\n",
    "    faces = detector.detect_faces(img)\n",
    "    # check if detected faces\n",
    "    if(len(faces)==0):\n",
    "        return #no face\n",
    "    bounding_box = bounding_box_check(faces,x,y)\n",
    "    if(bounding_box == None):\n",
    "        return\n",
    "    crop_img = img[bounding_box[1]:bounding_box[1] + bounding_box[3],bounding_box[0]:bounding_box[0]+bounding_box[2]]\n",
    "    crop_img = cv2.resize(crop_img,(160,160))\n",
    "    return crop_img;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prevent tensorflow from using GPU\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import librosa as lr;\n",
    "import logging;\n",
    "import cv2;\n",
    "import scipy.io.wavfile as wavfile;\n",
    "from mtcnn import MTCNN;\n",
    "from keras.models import load_model;\n",
    "from keras.models import Model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/layers/core.py:1028: UserWarning: inception_resnet_v1 is not loaded, but a Lambda layer uses it. It may cause errors.\n",
      "  warnings.warn('{} is not loaded, but a Lambda layer uses it. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# create a temporary directory for the downloaded files\n",
    "os.system(\"rm -rf tmp; mkdir tmp\");\n",
    "dest = 'tmp';\n",
    "\n",
    "# choose the data index to start processing at\n",
    "curr_ind = 1;\n",
    "\n",
    "# load the AVspeech URLs\n",
    "csv_data = pd.read_csv('train.csv');\n",
    "# csv_data = pd.read_csv('test.csv')\n",
    "\n",
    "# initialize models\n",
    "detector = MTCNN()\n",
    "model = load_model('facenet_keras.h5');\n",
    "avgPool_layer_model = Model(inputs=model.input,outputs=model.get_layer('AvgPool').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fba5c765700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fba5c765700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fba5c765700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fba5c765700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fba5c765700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fba5c765700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fba5c765700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception occured for file #2\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-9-4148d7a989c8>\", line 26, in <module>\n",
      "    crop_img = face_detect(filename, detector, \"tmp/\", x, y);\n",
      "  File \"<ipython-input-5-36d386d777aa>\", line 4, in face_detect\n",
      "    x = img.shape[1] * x\n",
      "AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "/home/dan/.local/lib/python3.8/site-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "ERROR:root:Exception occured for file #4\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dan/.local/lib/python3.8/site-packages/librosa/core/audio.py\", line 146, in load\n",
      "    with sf.SoundFile(path) as sf_desc:\n",
      "  File \"/home/dan/.local/lib/python3.8/site-packages/soundfile.py\", line 629, in __init__\n",
      "    self._file = self._open(file, mode_int, closefd)\n",
      "  File \"/home/dan/.local/lib/python3.8/site-packages/soundfile.py\", line 1183, in _open\n",
      "    _error_check(_snd.sf_error(file_ptr),\n",
      "  File \"/home/dan/.local/lib/python3.8/site-packages/soundfile.py\", line 1357, in _error_check\n",
      "    raise RuntimeError(prefix + _ffi.string(err_str).decode('utf-8', 'replace'))\n",
      "RuntimeError: Error opening 'tmp/preprocessed_4.wav': System error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-9-4148d7a989c8>\", line 20, in <module>\n",
      "    download_audio_video(dest, str(i_file), youtube_id, start_time, end_time)\n",
      "  File \"<ipython-input-1-072a12a82310>\", line 28, in download_audio_video\n",
      "    audio,_= lr.load(preprocessed_filename,sr=16000)\n",
      "  File \"/home/dan/.local/lib/python3.8/site-packages/librosa/core/audio.py\", line 163, in load\n",
      "    y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "  File \"/home/dan/.local/lib/python3.8/site-packages/librosa/core/audio.py\", line 187, in __audioread_load\n",
      "    with audioread.audio_open(path) as input_file:\n",
      "  File \"/home/dan/.local/lib/python3.8/site-packages/audioread/__init__.py\", line 111, in audio_open\n",
      "    return BackendClass(path)\n",
      "  File \"/home/dan/.local/lib/python3.8/site-packages/audioread/rawread.py\", line 62, in __init__\n",
      "    self._fh = open(filename, 'rb')\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'tmp/preprocessed_4.wav'\n",
      "ERROR:root:Exception occured for file #5\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-9-4148d7a989c8>\", line 26, in <module>\n",
      "    crop_img = face_detect(filename, detector, \"tmp/\", x, y);\n",
      "  File \"<ipython-input-5-36d386d777aa>\", line 4, in face_detect\n",
      "    x = img.shape[1] * x\n",
      "AttributeError: 'NoneType' object has no attribute 'shape'\n"
     ]
    }
   ],
   "source": [
    "for i_mixture in range(10000):\n",
    "    data_features = {\n",
    "        \"train\": 1,\n",
    "        \"test\" : 0,\n",
    "        \"ind\"  : [],\n",
    "        \"faces\": [],\n",
    "        \"av_pl\": [],\n",
    "        \"emb\"  : [],\n",
    "        \"stft\" : [],\n",
    "        \"mix\"  : [],\n",
    "        \"mask\" : [],\n",
    "    }\n",
    "    for i_file in range(curr_ind,curr_ind+20):\n",
    "        youtube_id = csv_data.loc[i_file,'link']\n",
    "        start_time = csv_data.loc[i_file,'start_time']\n",
    "        end_time   = csv_data.loc[i_file,'end_time']\n",
    "        x = csv_data.loc[i_file,'pos_x']\n",
    "        y = csv_data.loc[i_file,'pos_y']\n",
    "        try:\n",
    "            download_audio_video(dest, str(i_file), youtube_id, start_time, end_time)\n",
    "            face_emb_av_pl = np.zeros((75,1792));\n",
    "            face_emb = np.zeros((75,512));\n",
    "            video = np.zeros((75,160,160,3));\n",
    "            for i_frame in range(0,75):\n",
    "                filename = str(i_file)+\"-%02d.jpg\"%(i_frame+1);\n",
    "                crop_img = face_detect(filename, detector, \"tmp/\", x, y);\n",
    "                assert(np.shape(crop_img) == (160,160,3));\n",
    "                face = crop_img[np.newaxis,:,:,:];\n",
    "                video[i_frame,:,:,:] = face;\n",
    "                face_emb_av_pl[i_frame,:] = avgPool_layer_model.predict(face);\n",
    "                face_emb[i_frame,:] = model.predict(face);\n",
    "            filename = \"tmp/preprocessed_\" +str(i_file) + \".wav\";\n",
    "            x,sr = lr.load(filename,sr=16000, duration=3);\n",
    "            data_features[\"mix\"].append(x);\n",
    "            data_features[\"stft\"].append(stft(x));\n",
    "            data_features[\"faces\"].append(video);\n",
    "            data_features[\"av_pl\"].append(face_emb_av_pl);\n",
    "            data_features[\"emb\"].append(face_emb);\n",
    "            data_features[\"ind\"].append(i_file);\n",
    "        except:\n",
    "            logging.exception(\"Exception occured for file #\" + str(i_file));\n",
    "            continue;\n",
    "        if len(data_features[\"ind\"]) == 2:\n",
    "            curr_ind = i_file + 1;\n",
    "            break;\n",
    "    data_features[\"mix\"] = stft(data_features[\"mix\"][0]+data_features[\"mix\"][1]);\n",
    "    data_features[\"mask\"].append(complex_ratio_mask(data_features[\"mix\"],data_features[\"stft\"][0]))\n",
    "    data_features[\"mask\"].append(complex_ratio_mask(data_features[\"mix\"],data_features[\"stft\"][1]))\n",
    "    \n",
    "    save_filename = \"data/\"\n",
    "    save_filename += \"train\" if data_features[\"train\"] else \"test\"\n",
    "    save_filename += \"_\" + str(data_features[\"ind\"][0])\n",
    "    save_filename += \"_\" + str(data_features[\"ind\"][1])\n",
    "    np.save(save_filename,data_features,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
