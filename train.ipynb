{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob;\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, TensorBoard, LearningRateScheduler\n",
    "from tensorflow.keras.losses import LogCosh\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.losses import MeanAbsoluteError\n",
    "from tensorflow.keras.models import load_model\n",
    "from AV_model import AV_model\n",
    "from AVGenerator import AVGenerator;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_training = False\n",
    "\n",
    "if resume_training:\n",
    "    model_file = \"checkpoints/\"\n",
    "    model = load_model(model_file)\n",
    "else:\n",
    "    model = AV_model()\n",
    "    \n",
    "loss = MeanSquaredError()\n",
    "# loss = LogCosh()\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=1e-4),loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file = \"checkpoints/v5_lr1em4_mse_epoch-{epoch:03d}.h5\"\n",
    "checkpoint = ModelCheckpoint(checkpoint_file,verbose=1)\n",
    "tb = TensorBoard(log_dir='log5',update_freq='batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "515/515 [==============================] - ETA: 0s - loss: 0.1019\n",
      "Epoch 00001: saving model to checkpoints/v5_lr1em4_mse_epoch-001.h5\n",
      "515/515 [==============================] - 394s 764ms/step - loss: 0.1019 - val_loss: 0.1203\n",
      "Epoch 2/200\n",
      "515/515 [==============================] - ETA: 0s - loss: 0.0996\n",
      "Epoch 00002: saving model to checkpoints/v5_lr1em4_mse_epoch-002.h5\n",
      "515/515 [==============================] - 393s 763ms/step - loss: 0.0996 - val_loss: 0.1140\n",
      "Epoch 3/200\n",
      "515/515 [==============================] - ETA: 0s - loss: 0.0996\n",
      "Epoch 00003: saving model to checkpoints/v5_lr1em4_mse_epoch-003.h5\n",
      "515/515 [==============================] - 393s 764ms/step - loss: 0.0996 - val_loss: 0.1141\n",
      "Epoch 4/200\n",
      "515/515 [==============================] - ETA: 0s - loss: 0.0995\n",
      "Epoch 00004: saving model to checkpoints/v5_lr1em4_mse_epoch-004.h5\n",
      "515/515 [==============================] - 392s 762ms/step - loss: 0.0995 - val_loss: 0.1126\n",
      "Epoch 5/200\n",
      "515/515 [==============================] - ETA: 0s - loss: 0.0995\n",
      "Epoch 00005: saving model to checkpoints/v5_lr1em4_mse_epoch-005.h5\n",
      "515/515 [==============================] - 392s 762ms/step - loss: 0.0995 - val_loss: 0.1129\n",
      "Epoch 6/200\n",
      "515/515 [==============================] - ETA: 0s - loss: 0.0995\n",
      "Epoch 00006: saving model to checkpoints/v5_lr1em4_mse_epoch-006.h5\n",
      "515/515 [==============================] - 392s 762ms/step - loss: 0.0995 - val_loss: 0.1131\n",
      "Epoch 7/200\n",
      "515/515 [==============================] - ETA: 0s - loss: 0.0995\n",
      "Epoch 00007: saving model to checkpoints/v5_lr1em4_mse_epoch-007.h5\n",
      "515/515 [==============================] - 393s 763ms/step - loss: 0.0995 - val_loss: 0.1141\n",
      "Epoch 8/200\n",
      "515/515 [==============================] - ETA: 0s - loss: 0.0995\n",
      "Epoch 00008: saving model to checkpoints/v5_lr1em4_mse_epoch-008.h5\n",
      "515/515 [==============================] - 392s 762ms/step - loss: 0.0995 - val_loss: 0.1117\n",
      "Epoch 9/200\n",
      "515/515 [==============================] - ETA: 0s - loss: 0.0995\n",
      "Epoch 00009: saving model to checkpoints/v5_lr1em4_mse_epoch-009.h5\n",
      "515/515 [==============================] - 395s 767ms/step - loss: 0.0995 - val_loss: 0.1118\n",
      "Epoch 10/200\n",
      "515/515 [==============================] - ETA: 0s - loss: 0.0995\n",
      "Epoch 00010: saving model to checkpoints/v5_lr1em4_mse_epoch-010.h5\n",
      "515/515 [==============================] - 394s 764ms/step - loss: 0.0995 - val_loss: 0.1097\n",
      "Epoch 11/200\n",
      "180/515 [=========>....................] - ETA: 3:31 - loss: 0.0991"
     ]
    }
   ],
   "source": [
    "train_file_list = glob.glob(\"data/train*.npy\")\n",
    "test_file_list = glob.glob(\"data/test*.npy\")\n",
    "train_gen = AVGenerator(train_file_list,batch_size=1)\n",
    "test_gen = AVGenerator(test_file_list,batch_size=1)\n",
    "model.fit(x=train_gen,validation_data=test_gen,epochs=200,initial_epoch=0,callbacks=[checkpoint,tb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
